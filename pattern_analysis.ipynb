{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib import pyplot\n",
    "from numpy import linalg\n",
    "from numpy import random\n",
    "from random import sample\n",
    "from scipy import signal \n",
    "from scipy import stats\n",
    "from shapely.geometry import Point, Polygon\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from collections import defaultdict\n",
    "\n",
    "import dmr\n",
    "import datetime\n",
    "import foursquare\n",
    "import geopandas\n",
    "import math\n",
    "import numpy\n",
    "import pandas\n",
    "import pickle\n",
    "import pymongo\n",
    "import time\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_leaf = (5.0, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaf(name):\n",
    "    fig.savefig('lab_plot/'+name+'.eps', dpi=150, format='eps', transparent=True, pad_inches=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO maglia fine ds98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation_uri = 'http://dati.comune.milano.it/dataset/806829b9-134b-40cf-b0e0-03e66c4f76d7/resource/3e355dd1-a8b8-483d-ac4d-03a62232ef38/download/ace_maggio_2011.geojson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lantent Activity in Mobility Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_name = [\"Cultura\",\n",
    " \"Istruzione\",\n",
    " \"Eventi\",\n",
    " \"Cibi\",\n",
    " \"Lavoro\",\n",
    " \"Night\",\n",
    " \"Ricreativi\",\n",
    " \"Negozi\",\n",
    " \"Trasporti\",\n",
    " \"Residenza\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories_name = [\"Arte e intrattenimento\",\n",
    "#  \"Istituti superiori e università\",\n",
    "#  \"Eventi\",\n",
    "#  \"Cibi\",\n",
    "#  \"Posti professionali e altri\",\n",
    "#  \"Locali notturni\",\n",
    "#  \"All'aperto & Ricreativi\",\n",
    "#  \"Negozi e servizi\",\n",
    "#  \"Viaggi e trasporti\",\n",
    "#  \"Residenza\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern di mobilità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikemi_dataframe = pandas.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_lookup = {}\n",
    "fwd_lookup, bwd_lookup = {} , {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_bwd():\n",
    "    global bwd_lookup\n",
    "    bwd_lookup = { v:k for k,v in fwd_lookup.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_filter = [ 'Cliente'\n",
    "                  , 'Data_prelievo'\n",
    "                  , 'Gio_settimana_prelievo'\n",
    "                  , 'Festivo_feriale_prelievo'\n",
    "                  , 'Stazione_prelievo'\n",
    "                  , 'Durata_sec'\n",
    "                  , 'Data_arrivo'\n",
    "                  , 'Gio_settimana_arrivo'\n",
    "                  , 'Festivo_feriale_arrivo'\n",
    "                  , 'Stazione_arrivo'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unione dei dataframe\n",
    "# for yy in range(2015, 2019): \n",
    "#     for mm in range(1, 13):\n",
    "#         try:\n",
    "#             csv_uri = '/home/datasets/bikemi/{0}/{1:02d} {0}.csv'.format(yy,mm)\n",
    "#             next_df = pandas.read_csv(csv_uri,\n",
    "#                            lineterminator ='\\r',\n",
    "#                            encoding = 'iso8859_2',\n",
    "#                            sep = ';',\n",
    "#                            parse_dates = ['Data_prelievo','Data_arrivo'],\n",
    "#                            date_parser = lambda x: datetime.datetime.strptime(x,'%d/%m/%y %H:%M'),\n",
    "#                            decimal = '.'\n",
    "#                           )\n",
    "            \n",
    "#         except FileNotFoundError:\n",
    "#             pass\n",
    "#         else:\n",
    "#             print(yy,mm,end='\\r')\n",
    "#             for _, i in next_df.iterrows():\n",
    "                \n",
    "# #                 # LOOKUP\n",
    "# #                 a = i['Stazione_prelievo']\n",
    "# #                 b = i['Stazione_arrivo']\n",
    "                \n",
    "# #                 if a not in station_lookup:\n",
    "# #                     station_lookup[a] = {i['Nome_stazione_prelievo']}\n",
    "# #                 else:\n",
    "# #                     station_lookup[a].add(i['Nome_stazione_prelievo'])\n",
    "                    \n",
    "# #                 if b not in station_lookup:\n",
    "# #                     station_lookup[b] = {i['Nome_stazione_arrivo']}\n",
    "# #                 else:\n",
    "# #                     station_lookup[b].add(i['Nome_stazione_arrivo'])\n",
    "#                 pass\n",
    "                \n",
    "#             #SAVE\n",
    "#             bikemi_dataframe = pandas.concat([bikemi_dataframe, next_df[columns_filter]])\n",
    "\n",
    "\n",
    "# pickle.dump(bikemi_dataframe, open( \"archive/bikemi_dataframe.pkl\", \"wb\" ) )\n",
    "# # pickle.dump(station_lookup, open( \"archive/station_lookup.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikemi_dataframe = pickle.load(open('archive/bikemi_dataframe.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pickle.load(open('archive/station_lookup.pkl', 'rb'))\n",
    "station_lookup = {k:list(v)[0] for k,v in tmp.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps = pickle.load(open('/home/datasets/bikemi/station_gps_location.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correzione stazioni "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stazioni inutilizzate\n",
    "for i in list(gps):\n",
    "    if i not in station_lookup:\n",
    "        del gps[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stazioni mancanti\n",
    "gps[2] = gps[402]\n",
    "gps[903] = gps[263]\n",
    "\n",
    "gps[90] = (45.484649, 9.195576)\n",
    "gps[92] = (45.465589, 9.186123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relookupping\n",
    "new_gps = []\n",
    "for i in range(max(gps)+1):\n",
    "    if i in gps:\n",
    "        fwd_lookup[i] = len(new_gps)\n",
    "        new_gps.append(gps[i])\n",
    "gps = new_gps\n",
    "update_bwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correzione POIs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4square\n",
    "CLIENT_ID = 'XDNRQIG15QP4PUZEMAGGVBPYHV1WXQMFXXAXZM410USDSTC3'\n",
    "CLIENT_SECRET = 'M55BW0UXPLUGACETI5ENMSF3WXGLDIENZAHE5VXPPVBYLSWO'\n",
    "client = foursquare.Foursquare(client_id=CLIENT_ID, client_secret=CLIENT_SECRET)\n",
    "categories = client.venues.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO rimozione delle 10 categorie madri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup macrocateg\n",
    "category_lookup = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_category(c):\n",
    "    if not c['categories']:\n",
    "        return [(c['id'],c['name'])]\n",
    "    else:\n",
    "        l = [(c['id'],c['name'])]\n",
    "        for ca in c['categories']:\n",
    "            l.extend(extract_category(ca))\n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for macro_category in categories['categories']:\n",
    "    for id_cat, name_cat in extract_category(macro_category):\n",
    "        category_lookup[id_cat] = (macro_category['id'],macro_category['name'],name_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4square DB\n",
    "mongo_conn = pymongo.MongoClient(\"mongodb://marvin.nptlab.di.unimi.it\")\n",
    "six_db = mongo_conn['FoursquarePlacesMilan']\n",
    "places = six_db['places']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pois = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulizia POIS\n",
    "for i in places.find():\n",
    "        tmp = {\n",
    "            'name':i['name'],\n",
    "            'location':(\n",
    "                float(i['location']['lat']['$numberDouble']),\n",
    "                float(i['location']['lng']['$numberDouble'])\n",
    "            ),\n",
    "            'categories':{category_lookup[j['id']][0] for j in i['categories']}\n",
    "        }\n",
    "        pois.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tassellamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_aces = geopandas.read_file(tessellation_uri)\n",
    "vor = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.variation([i for i in raw_aces.geometry.area])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = [pois[i]['location'][0] for i in range(len(pois))], [pois[i]['location'][1] for i in range(len(pois))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = raw_aces.plot(figsize=sq_leaf, color='dimgray', edgecolor='white', alpha=1.0)\n",
    "fig = plot.get_figure()\n",
    "ax = fig.gca()\n",
    "ax.plot(x, y, marker='.',ms=0.2, linestyle='', color='orangered')\n",
    "ax.set_xlim(9.06, 9.28)\n",
    "ax.set_ylim(45.39, 45.54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf('pois-galaxy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poligoni delle regioni\n",
    "for _, r in raw_aces.iterrows():\n",
    "    lat = r.geometry.exterior.xy[1]\n",
    "    lng = r.geometry.exterior.xy[0]\n",
    "    vor[int(r.ACE)-1] = Polygon([(lat[i], lng[i]) for i in range(len(lat))]) # L'ARRAY ACE PARTE DA 1\n",
    "\n",
    "vor = numpy.array([vor[i] for i in range(len(vor))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relookupping\n",
    "for g in range(len(gps)):\n",
    "    for r in range(len(vor)):\n",
    "        if vor[r].contains(Point(gps[g])):\n",
    "            fwd_lookup[bwd_lookup[g]] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [float(i+1) for i in list(set(fwd_lookup.values()))]\n",
    "qqq = raw_aces[raw_aces.ACE.isin(tmp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = qqq.plot(figsize=sq_leaf, color='dimgray', edgecolor='white', alpha=1.0)\n",
    "fig = plot.get_figure()\n",
    "ax = fig.gca()\n",
    "ax.set_xlim(9.085, 9.24)\n",
    "ax.set_ylim(45.42, 45.54)\n",
    "x, y = [gps[i][1] for i in range(len(gps))], [gps[i][0] for i in range(len(gps))]\n",
    "ax.plot(x, y, marker='.',ms=3.75, linestyle='', color='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf('bikemi-galaxy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regioni non vuote\n",
    "unempty = numpy.array([True]*len(vor))\n",
    "for r in range(len(vor)):\n",
    "    unempty[r] = r in fwd_lookup.values()\n",
    "\n",
    "vor = vor[unempty]\n",
    "# vor = vor[list(set(fwd_lookup.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relookupping\n",
    "for k,v in dict(zip((i for i, kept in enumerate(unempty) if kept), range(len(vor)))).items():\n",
    "    for f,b in fwd_lookup.items():\n",
    "        if b == k:\n",
    "            fwd_lookup[f] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF e SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorie: solo quelle usate, senza lista completa\n",
    "categories = set()\n",
    "for i in pois:\n",
    "    for j in i['categories']: \n",
    "        categories.add(j)\n",
    "categories = list(categories)\n",
    "categories.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequenze assolute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abs_frequencies = numpy.zeros([len(vor), len(categories)])\n",
    "# for r in range(len(vor)):\n",
    "#     for p in pois:\n",
    "#         if vor[r].contains(Point(p['location'])):\n",
    "#             for k in p['categories']:\n",
    "#                 abs_frequencies[r, categories.index(k)] += 1\n",
    "# pickle.dump(abs_frequencies, open( \"archive/abs_frequencies.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abs_frequencies = numpy.zeros([len(vor), len(categories)])\n",
    "# for r in range(len(vor)):\n",
    "#     for p in pois:\n",
    "#         if vor[r].contains(Point(p['location'])):\n",
    "#             for k in p['categories']:\n",
    "#                 abs_frequencies[r, random.choice(len(categories))] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_frequencies = pickle.load(open('archive/abs_frequencies.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abs_frequencies = numpy.delete(abs_frequencies, 2, 1)\n",
    "# del categories[2]\n",
    "# del categories_name[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_cat = [sum(abs_frequencies[:,k]) for k in range(len(categories))] # n° poi per categoria\n",
    "dim_reg = [sum(abs_frequencies[r,:]) for r in range(len(vor))] # n°  poi per regione\n",
    "num_reg = [len(abs_frequencies[:,k][abs_frequencies[:,k] != 0]) for k in range(len(categories))] # n° regioni per categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.figure(figsize=sq_leaf)\n",
    "ax = fig.gca()\n",
    "ax.barh(categories_name, dim_cat, color='darkgreen', log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf('category-hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = numpy.zeros([len(vor),len(categories)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(vor)):\n",
    "    for j in range(len(categories)):\n",
    "        tf = dim_cat[j]/dim_reg[i]\n",
    "        idf = len(vor)/num_reg[j]\n",
    "        tf_idf[i,j] = tf*1 # math.log(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, v = linalg.svd(tf_idf, full_matrices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO low-rank di s, e U, V ridotte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collaborative features\n",
    "fig = pyplot.figure(figsize=sq_leaf)\n",
    "ax = fig.gca()\n",
    "ax = seaborn.heatmap(tf_idf, linewidth=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuboidi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_gran = 60*10\n",
    "time_max = 60*60*18*2\n",
    "time_bin = [i for i in range(0,time_max,time_gran)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_time_bin(t,f):\n",
    "    return int((60*(60*(18*(f)+((t.hour+17)%24))+t.minute)+t.second)/time_gran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bin_rev_i(i):\n",
    "#     i *= time_gran\n",
    "#     l = int(i/(60*60*24*2*len(vor))%(2))\n",
    "#     r = int(i/(60*60*24*2)%(len(vor)))\n",
    "#     f = int(i/(60*60*24)%(2))\n",
    "#     h = int(i/(60*60)%(24))\n",
    "#     m = int(i/(60)%(60))\n",
    "#     return {'arriving_or_leaving':l, 'region':r, 'work_or_holy':f, 'hour':h, 'min':m}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arriving_cuboid = numpy.zeros([len(vor), len(vor), len(time_bin)])\n",
    "leaving_cuboid = numpy.zeros([len(vor), len(vor), len(time_bin)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_users = numpy.array([[[set()]*len(time_bin)]*len(vor)]*len(vor))\n",
    "leav_users = numpy.array([[[set()]*len(time_bin)]*len(vor)]*len(vor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, r in bikemi_dataframe.iterrows():\n",
    "#     src = fwd_lookup[r['Stazione_prelievo']]\n",
    "#     dst = fwd_lookup[r['Stazione_arrivo']]\n",
    "#     intr = range(1,7)\n",
    "    \n",
    "#     if(r['Data_arrivo'].hour not in intr and r['Data_prelievo'].hour not in intr):\n",
    "        \n",
    "#         arr_time = i_time_bin(r['Data_arrivo'], r['Festivo_feriale_arrivo'])\n",
    "#         leav_time = i_time_bin(r['Data_prelievo'], r['Festivo_feriale_prelievo'])\n",
    "#         usr = r['Cliente']\n",
    "        \n",
    "#         if usr not in arr_users[src, dst, arr_time]:\n",
    "#             arriving_cuboid[src, dst, arr_time] += 1\n",
    "#             arr_users[src, dst, arr_time].add(usr)\n",
    "#         if usr not in leav_users[src, dst, leav_time]:\n",
    "#             leaving_cuboid[src, dst, leav_time] += 1\n",
    "#             leav_users[src, dst, arr_time].add(usr)\n",
    "        \n",
    "# pickle.dump(arriving_cuboid, open( \"archive/arriving_cuboid.pkl\", \"wb\"))\n",
    "# pickle.dump(leaving_cuboid, open( \"archive/leaving_cuboid.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arriving_cuboid = pickle.load(open('archive/arriving_cuboid.pkl', 'rb'))\n",
    "leaving_cuboid = pickle.load(open('archive/leaving_cuboid.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(len(vor)):\n",
    "    a = arriving_cuboid[:,r,:].ravel()\n",
    "    l = leaving_cuboid[r,:,:].ravel()\n",
    "    m = a + l\n",
    "    v = u[r]+[1]\n",
    "    docs[r] = {'v':v, 'm':m}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(numpy.array([docs[r]['m'] for r in range(len(vor))]).ravel())\n",
    "vocab = list(vocab)\n",
    "vocab.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for r in range(len(vor)):\n",
    "    tmp += docs[r]['m'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.figure(figsize=sq_leaf)\n",
    "ax = fig.gca()\n",
    "eps = 1\n",
    "yell = 1\n",
    "y, x = numpy.histogram(tmp, numpy.arange(0, max(tmp)+eps, eps))\n",
    "ax.plot(x[yell:-1], y[yell:], marker='.',ms=5.5, linestyle='', color='maroon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # remove zeros?\n",
    "# docs[r]['m'] = docs[r]['m'][ docs[r]['m'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = pyplot.figure(figsize=sq_leaf)\n",
    "# ax = fig.gca()\n",
    "# ecdf = ECDF(tmp)\n",
    "# ax.plot(ecdf.x, ecdf.y, marker='.',ms=0.1, linestyle='--', color='coral')\n",
    "# ax.set_xlim(0, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy.mean(tmp), numpy.percentile(tmp, 50), numpy.std(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Probablilità congiunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = numpy.zeros([len(vor), len(categories)])\n",
    "for r in range(len(abs_frequencies)):\n",
    "    probs[r] = abs_frequencies[r]/numpy.sum(abs_frequencies[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(probs, open(\"means_k/probs/probs.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_probs = numpy.zeros([len(vor),len(vor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users = numpy.array([[set()]*len(vor)]*len(vor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, r in bikemi_dataframe.iterrows():\n",
    "#     src = fwd_lookup[r['Stazione_prelievo']]\n",
    "#     dst = fwd_lookup[r['Stazione_arrivo']]\n",
    "#     usr = r['Cliente']\n",
    "\n",
    "#     if usr not in users[src, dst]:\n",
    "#         move_probs[src, dst] += 1\n",
    "#         users[src, dst].add(usr)\n",
    "            \n",
    "# pickle.dump(move_probs, open( \"archive/move_probs.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_probs = pickle.load(open( \"archive/move_probs.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conj_probs = numpy.zeros([len(categories),len(categories)])\n",
    "tmp = numpy.sum(move_probs)\n",
    "for ks in range(len(categories)):\n",
    "    for kd in range(len(categories)):\n",
    "        for rs in range(len(vor)):\n",
    "            for rd in range(len(vor)):\n",
    "                conj_probs[ks,kd] += probs[rs,ks]*probs[rd,kd]*move_probs[rs,rd]/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_probs = numpy.zeros([len(categories),len(categories)])\n",
    "for ks in range(len(categories)):\n",
    "    tmp = numpy.sum(conj_probs[ks,:])\n",
    "    for kd in range(len(categories)):\n",
    "        cond_probs[ks,kd] = conj_probs[ks,kd]/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Category ditribution over each region\n",
    "\n",
    "fig = pyplot.figure(figsize=sq_leaf)\n",
    "ax = fig.gca()\n",
    "# ax = seaborn.heatmap(abs_frequencies, linewidth=0.5)\n",
    "ax = seaborn.heatmap(probs, linewidth=0.05)\n",
    "# ax = seaborn.heatmap(move_probs, linewidth=0.5)\n",
    "# ax = seaborn.heatmap(conj_probs, linewidth=0.5)\n",
    "# ax = seaborn.heatmap(cond_probs, linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "{categories_name.index(i):i for i in categories_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diriclet Multinomial Regression di Kato "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        '''\n",
    "            - z_m_n: topics assigned to word slots in documents\n",
    "            - n_m_z: freq. of topics assigned to documents\n",
    "            - n_z_w: freq. of words assigned to topics\n",
    "            - n_z:   freq. of topics assigned\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, coeff_vecs = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "K = 10\n",
    "sigma = 0.01\n",
    "beta = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(len(docs)):\n",
    "    corpus.append(numpy.array(docs[r]['m']))\n",
    "    coeff_vecs.append(numpy.array(docs[r]['v']))\n",
    "corpus, coeff_vecs = numpy.array(corpus), numpy.array(coeff_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning\n",
    "voca = dmr.Vocabulary()\n",
    "doku = voca.read_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = dmr.DMR(K, sigma, beta, doku, coeff_vecs, voca.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(corpus, open( \"kato_dmr/corpus.pkl\", \"wb\" ) )\n",
    "# pickle.dump(coeff_vecs, open( \"kato_dmr/coeff_vecs.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.learning(iteration=150, voca=voca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda = pickle.load(open(\"kato_dmr/55lda.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # topic probability of each document\n",
    "# tdist = lda.topicdist()\n",
    "# extracted = []\n",
    "# for doc, vec, td in zip(corpus, vecs, tdist):\n",
    "#     print(\"For: \", doc, \"Max topic: \", np.argmax(td), \"Max prob.: \", np.max(td))\n",
    "#     #print(\"ALPHA\", np.dot(vec, lda.Lambda.T))\n",
    "#     extracted.append(np.argmax(td))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = lda.topicdist() # topic probability of each document\n",
    "numpy.shape(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = lda.worddist() # word probability of each topic\n",
    "numpy.shape(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = lda.z_m_n # maybe\n",
    "numpy.shape(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region-Topic Heatmap  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_heat = th\n",
    "fig = pyplot.figure(figsize=sq_leaf)\n",
    "ax = fig.gca()\n",
    "ax = seaborn.heatmap(cat_heat, linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lda.n_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = pyplot.figure(figsize=sq_leaf)\n",
    "ax = fig.gca()\n",
    "ax.bar(range(len(y)),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_a, arr_or_leav, reg_b, work_or_holy, hh, mm = fwd_lookup[162], 0, fwd_lookup[56], 0, 9, 20\n",
    "i = (24*(2*(50*(arr_or_leav)+reg_b)+work_or_holy)+hh)+int(mm/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.savefig('15iter_topic_assig.png', dpi=600)\n",
    "# pickle.dump(lda.n_m_z, open( \"means_k/kato.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(th)):\n",
    "    th[i] /= numpy.sum(th[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(probs, open(\"means_k/probs/probs.pkl\", \"wb\"))\n",
    "pickle.dump(th, open(\"means_k/kato/kato.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementate k-means qui è improponibile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_clust = pickle.load(open(\"means_k/probs/probs_avg.pkl\",\"rb\"))\n",
    "post_clust = pickle.load(open(\"means_k/kato/kato_avg.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score post-lda\n",
    "y = [post_clust[1][i] for i in post_clust[1]]\n",
    "fig = pyplot.figure(figsize=sq_leaf)\n",
    "ax = fig.gca()\n",
    "ax.plot(list(post_clust[1].keys()), y, marker='o',ms=5.5, linestyle='-', color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_mutual_info_score(pre_clust[0][10],post_clust[0][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = pre_clust[0][10], post_clust[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proper_index(a, b):\n",
    "    metrics = {}\n",
    "    for label in set(a):\n",
    "        metrics[label] = [0.0, 0.0]\n",
    "        inner_labels = set(b[numpy.where(a == label)])\n",
    "        for proper_label in inner_labels:\n",
    "            t_set = set(numpy.where(b == proper_label)[0])\n",
    "            a_set = set(numpy.where(a == label)[0])\n",
    "            metrics[label][0] += len(t_set - a_set)\n",
    "            metrics[label][1] += len(t_set)\n",
    "        metrics[label] = metrics[label][0] / metrics[label][1]\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=[]\n",
    "for a in pre_clust[0].values():\n",
    "    for b in post_clust[0].values():\n",
    "        tmp.append(list(proper_index(a, b).values()))\n",
    "fig = pyplot.figure(figsize=sq_leaf)\n",
    "ax = fig.gca()\n",
    "ax.boxplot(tmp) # pre k = varianza , post k= propritetà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leaf(fig,'improprity-distro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample algorthm try\n",
    "n = 4\n",
    "x = numpy.array([i for i in range(n) for j in range(n)])\n",
    "y = numpy.array([i for i in range(int(n/2)) for j in range(n*2)])\n",
    "proper_index(y,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRM di Zheng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zheng_z = pickle.load(open(\"zheng_dmr/z.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = zheng_z\n",
    "t = [ tmp[j][i] for j in range(len(tmp)) for i in range(len(tmp[j])) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.figure(figsize=sq_leaf)\n",
    "ax = fig.gca()\n",
    "y, x = numpy.histogram(t, numpy.arange(0, max(t)+2, 1))\n",
    "ax.plot(x[:-1], y, marker='.',ms=11.0, linestyle='', color='purple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = {}\n",
    "for i, r in bikemi_dataframe.iterrows():\n",
    "    t = r.Data_prelievo.date()\n",
    "    if t not in qt:\n",
    "        qt[t] = set()\n",
    "    qt[t].add(r['Cliente'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [len(i) for i in qt.values()]\n",
    "fig = pyplot.figure(figsize=sq_leaf)\n",
    "ax = fig.gca()\n",
    "eps = 400\n",
    "yell = 0\n",
    "y, x = numpy.histogram(tmp, numpy.arange(0, max(tmp)+eps, eps))\n",
    "ax.plot(x[yell:-1], y[yell:], marker='.',ms=5.5, linestyle='-', color='maroon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.figure(figsize=sq_leaf)\n",
    "ax = fig.gca()\n",
    "from scipy import stats\n",
    "stats.probplot(tmp, dist=\"norm\", plot=ax)\n",
    "# pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.mean(tmp), numpy.median(tmp), numpy.percentile(tmp, 25), numpy.percentile(tmp, 75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python BikeMI",
   "language": "python",
   "name": "bikemi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
